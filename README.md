# Neural-Networks-MLP: Multi-layer Percptron

Neural Networks can do following tasks : 1. Regression Task
                                         2. Classification Task
 
Training a NN is computationally very expensive but availability of relatively cheap computing resources has became one of the major reason for NN to become very popular 

Neural networks can have many different forms or architectures.
Multi Layered Perceptron (MLP) is basic neural network architecture.

Neural networks are inspired from human brain
Common belief about the working of human brain - the brains react to a stimulus by automatically activating certain biological neurons
When humans see something, the sight signal is passed to the brain by the eyes

Brain: Contains many neurons that are interconnected but Responds to different inputs differently by activating only a few neurons

Similarly Artificial Neurons create an artificial representation of a biological brain Start together artificial neurons creating a neural network
Artificial neurons behave the same way as our biological neurons Receive an input from other neurons and amplify that input to create an output which is in turn consumed by other neurons

Biological neurons amplify the input To amplify the input of an artificial neuron, the weighted sum is passed to an activation function
Many popular activation functions
used in neural networks
• Sigmoid =
1/(1+𝑒−𝑧)
• Relu = 𝑚𝑎𝑥(0, 𝑧)
• Tanh =(𝑒^𝑧 − 𝑒^−𝑧)/(𝑒^𝑧 + 𝑒^−𝑧)
